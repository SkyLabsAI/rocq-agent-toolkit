### FastAPI Backend: Phase 1 Overview

We are building a **FastAPI backend** to serve data to a frontend for visualization. The server will aggregate data from local agent runs and an observability stack.

---

### Architecture & Scope

* **Phase 1 (Current):** The server will run locally, reading `jsonl` result files generated by `brick_agent` directly from the local filesystem.
* **Future Roadmap:** The architecture will evolve to be centralized (using a database instead of files) and eventually be made public.

---

### Configuration

The server will be configured via a `.env` file that must define:
1.  The **local folder path** containing the `jsonl` run results.
2.  The **port** where the observability stack is accessible.

---

### Phase 1 API Endpoints

1.  **List All Agents**
    * **Action:** Scans all `jsonl` files to find and return a list of unique `agent_name` values.
2.  **List Runs by Agent**
    * **Action:** Provides a list of all runs associated with a specific agent.
3.  **Get Run Details**
    * **Action:** Returns the complete content (all `jsonl` entries) associated with a specific `run_id`.
    (take multiple run_ids and return complete content of all the files ) 
4. **Get Observability Logs**
    * **Action:** Based on the run_id and task_id fetch the observability logs


### Important 
To ensure maintainability, we will abstract the data access logic from the main API endpoints.
Core logic (like finding unique agents or fetching runs) will be isolated in dedicated functions. The API routes will simply call these functions. This design allows us to easily swap the data source (e.g., from reading local files to querying a database) by only updating the logic inside those specific functions, without needing to change the API endpoints themselves.


# Sample Schema
{
    "run_id": "5d5840cf-f953-4b51-847d-4b51484f9854",
    "task_kind": "FullProofTask",
    "task_id": "SumUpToN.v#lemma:test_ok",
    "timestamp_utc": "2025-11-06T06:38:56.167135+00:00",
    "agent_name": "o4MiniCodeProofAgent",
    "status": "Success",
    "metrics": {
        "llm_invocation_count": 0,
        "token_counts": {
            "input_tokens": 0,
            "output_tokens": 0,
            "total_tokens": 0
        },
        "resource_usage": {
            "execution_time_sec": 0.0,
            "cpu_time_sec": 0.0,
            "gpu_time_sec": 0.0
        },
        "custom": null
    },
    "results": "verify_spec; go.\nwp_for (fun \u03c1 => Exists i' sum', _local \u03c1 \"i\" |-> intR 1$m i' ** _local \u03c1 \"sum\" |-> intR 1$m sum' ** [| 2 * sum' = (i' - 1) * i' /\\ 1 <= i' <= n + 1 |])%Z; try go."
}
{
    "run_id": "5d5840cf-f953-4b51-847d-4b51484f9854",
    "task_kind": "FullProofTask",
    "task_id": "AddArrays.v#lemma:test_ok",
    "timestamp_utc": "2025-11-06T06:39:30.082665+00:00",
    "agent_name": "o4MiniCodeProofAgent",
    "status": "Failure",
    "metrics": {
        "llm_invocation_count": 2,
        "token_counts": {
            "input_tokens": 6354,
            "output_tokens": 803,
            "total_tokens": 7157
        },
        "resource_usage": {
            "execution_time_sec": 0.0,
            "cpu_time_sec": 0.0,
            "gpu_time_sec": 0.0
        },
        "custom": null
    },
    "failure_reason": [
        "Other",
        "failure: FailureReason(value=ResourceExhaustion(value=ResourceExhaustionKind(value=MaxLLMCalls(value=3))))"
    ],
    "results": "verify_spec; go.\ngo."
}


------------------------------

# Brick Agent Toolkit Backend - Setup Guide

## Overview
This is a FastAPI backend server that serves brick_agent task results for visualization in a frontend application.

## Installation

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure Environment**
   
   Create a `.env` file in the backend directory with the following variables:
   
   ```env
   # Path to the directory containing JSONL result files
   JSONL_RESULTS_PATH=/home/skylabs/Desktop/psi-verifier/workspace/psi/backend/brick_agents
   
   # Port where observability stack is accessible
   OBSERVABILITY_PORT=3010
   
   # Server configuration (optional)
   SERVER_HOST=0.0.0.0
   SERVER_PORT=8000
   ```

## Running the Server

### Development Mode (with auto-reload)
```bash
uv run python src/backend/main.py
```

### Production Mode
```bash
uvicorn main:app --host 0.0.0.0 --port 8000
```